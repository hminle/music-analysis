{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/dfLongterm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea1</th>\n",
       "      <th>fea2</th>\n",
       "      <th>fea3</th>\n",
       "      <th>fea4</th>\n",
       "      <th>fea5</th>\n",
       "      <th>fea6</th>\n",
       "      <th>fea7</th>\n",
       "      <th>fea8</th>\n",
       "      <th>fea9</th>\n",
       "      <th>fea10</th>\n",
       "      <th>...</th>\n",
       "      <th>fea24</th>\n",
       "      <th>fea25</th>\n",
       "      <th>fea26</th>\n",
       "      <th>fea27</th>\n",
       "      <th>fea28</th>\n",
       "      <th>fea29</th>\n",
       "      <th>fea30</th>\n",
       "      <th>fea31</th>\n",
       "      <th>fea32</th>\n",
       "      <th>fea33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.14</td>\n",
       "      <td>-210.30</td>\n",
       "      <td>70.38</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>13.52</td>\n",
       "      <td>7.67</td>\n",
       "      <td>9.21</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.00</td>\n",
       "      <td>-321.79</td>\n",
       "      <td>105.26</td>\n",
       "      <td>16.30</td>\n",
       "      <td>33.23</td>\n",
       "      <td>11.20</td>\n",
       "      <td>28.95</td>\n",
       "      <td>12.95</td>\n",
       "      <td>16.30</td>\n",
       "      <td>2.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174.55</td>\n",
       "      <td>-216.06</td>\n",
       "      <td>88.31</td>\n",
       "      <td>-8.95</td>\n",
       "      <td>41.89</td>\n",
       "      <td>18.97</td>\n",
       "      <td>7.79</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.23</td>\n",
       "      <td>-185.45</td>\n",
       "      <td>85.01</td>\n",
       "      <td>-8.47</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-17.62</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-14.41</td>\n",
       "      <td>-8.74</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.00</td>\n",
       "      <td>-209.14</td>\n",
       "      <td>69.00</td>\n",
       "      <td>30.20</td>\n",
       "      <td>31.84</td>\n",
       "      <td>14.17</td>\n",
       "      <td>22.39</td>\n",
       "      <td>5.16</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fea1    fea2    fea3   fea4   fea5   fea6   fea7   fea8   fea9  fea10  \\\n",
       "0  137.14 -210.30   70.38  -1.80  13.52   7.67   9.21  -4.23   3.85  -2.07   \n",
       "1   96.00 -321.79  105.26  16.30  33.23  11.20  28.95  12.95  16.30   2.92   \n",
       "2  174.55 -216.06   88.31  -8.95  41.89  18.97   7.79  -2.24   5.94   0.00   \n",
       "3   49.23 -185.45   85.01  -8.47   3.75 -17.62   6.10 -14.41  -8.74  -7.15   \n",
       "4  120.00 -209.14   69.00  30.20  31.84  14.17  22.39   5.16  12.23   0.63   \n",
       "\n",
       "   ...    fea24  fea25  fea26  fea27  fea28  fea29  fea30  fea31  fea32  fea33  \n",
       "0  ...     0.33   0.34   0.41   0.43   0.20   0.17   0.26   0.54   0.42   0.45  \n",
       "1  ...     0.55   0.59   0.41   0.38   0.27   0.22   0.09   0.05   0.12   0.25  \n",
       "2  ...     0.25   0.21   0.44   0.21   0.09   0.18   0.31   0.67   0.40   0.53  \n",
       "3  ...     0.24   0.50   0.53   0.20   0.26   0.09   0.14   0.17   0.31   0.33  \n",
       "4  ...     0.03   0.06   0.12   0.22   0.23   0.18   0.17   0.17   0.43   0.82  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('../data/dfY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>arousal_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  song_id  valence_mean  arousal_mean\n",
       "0      0        2           3.1           3.0\n",
       "1      1        3           3.5           3.3\n",
       "2      2        4           5.7           5.5\n",
       "3      3        5           4.4           5.3\n",
       "4      4        7           5.8           6.4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([data,y['valence_mean'], y['arousal_mean']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 15 #number of variables for heatmap\n",
    "corrmat = df.corr()\n",
    "cols = corrmat.nlargest(k, 'valence_mean')['valence_mean'].index\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scaled = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65519038, -0.07628927, -0.77544214, -0.03422748, -0.76500356,\n",
       "        0.62507754,  0.2090739 , -0.23296932,  0.16704597,  0.30380077,\n",
       "       -0.12093146,  0.84937125,  0.6236305 , -0.73196571,  1.23342518,\n",
       "        0.64840883, -0.29515861,  0.66941854,  0.67054655,  0.07763418,\n",
       "        0.35497932,  0.65683281, -0.80359708, -0.09453569,  0.11972583,\n",
       "        0.34251675,  0.6077862 , -0.7165535 , -0.99956607, -0.43536672,\n",
       "        0.91738949,  0.36843219,  0.42423349])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelTest(clf, train, labels):\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=45).split(train)\n",
    "    mse = make_scorer(mean_squared_error)\n",
    "    mse_val_score = cross_val_score(clf, train, labels, cv=cv, scoring=mse)\n",
    "    scores=[mse_val_score.mean()]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelPlot(result_dict):\n",
    "    result = pd.DataFrame.from_dict(result_dict, orient='index')\n",
    "    result.columns = [\"Mean Squared Error\"] \n",
    "    result = result.sort(columns=[\"Mean Squared Error\"],ascending=False)\n",
    "    #print(result)\n",
    "    result.plot(kind=\"bar\",title=\"Model Scores\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.5,1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelFit(train, labels):\n",
    "    result_dict = {}\n",
    "    \n",
    "    clf = linear_model.LinearRegression()\n",
    "    result_dict[\"Linear\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=1e-4)\n",
    "    result_dict[\"Lasso\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.Ridge()\n",
    "    result_dict[\"Ridge\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.BayesianRidge()\n",
    "    result_dict[\"Bayesian Ridge\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.HuberRegressor()\n",
    "    result_dict[\"Huber\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    result_dict[\"SVM RBF\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = svm.SVR(kernel=\"linear\")\n",
    "    result_dict[\"SVM Linear\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = BaggingRegressor()\n",
    "    result_dict[\"Bagging\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    result_dict[\"RandomForest\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = AdaBoostRegressor()\n",
    "    result_dict[\"AdaBoost\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    result_dict[\"XGBoost\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    model_summary = modelPlot(result_dict)\n",
    "    return model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelFit(data_scaled, y['valence_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(model, data, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_valence = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828713435051\n"
     ]
    }
   ],
   "source": [
    "create_model(clf_valence, data.as_matrix(), np.array(y['valence_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0859522334\n"
     ]
    }
   ],
   "source": [
    "clf_arousal = XGBRegressor()\n",
    "create_model(clf_arousal, data.as_matrix(), np.array(y['arousal_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_arousal_ridge = linear_model.Ridge()\n",
    "create_model(clf_arousal_ridge, data_scaled, np.array(y['arousal_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compare_arousal = pd.DataFrame({\"arousal_target\": y_test['arousal_mean'], \"arousal_pred\": y_pred_arousal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arousal_pred</th>\n",
       "      <th>arousal_target</th>\n",
       "      <th>ErrorRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595.000000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.829609</td>\n",
       "      <td>4.834353</td>\n",
       "      <td>0.198640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.818259</td>\n",
       "      <td>1.291042</td>\n",
       "      <td>0.202932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.746579</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.226549</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.063272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.920983</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.150523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.480211</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.249885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.869541</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>1.595567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       arousal_pred  arousal_target   ErrorRate\n",
       "count    595.000000      595.000000  595.000000\n",
       "mean       4.829609        4.834353    0.198640\n",
       "std        0.818259        1.291042    0.202932\n",
       "min        2.746579        2.000000    0.000112\n",
       "25%        4.226549        3.800000    0.063272\n",
       "50%        4.920983        4.900000    0.150523\n",
       "75%        5.480211        5.800000    0.249885\n",
       "max        6.869541        7.700000    1.595567"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_arousal['ErrorRate']= df_compare_arousal.apply(lambda row: abs(row['arousal_pred']-row['arousal_target'])/row['arousal_target'], axis=1)\n",
    "df_compare_arousal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame({\"valence_target\": y_test['valence_mean'], \"valence_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_pred</th>\n",
       "      <th>valence_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>2.455784</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>2.336570</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1.844455</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.247237</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>2.380033</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_pred  valence_target\n",
       "1554      2.455784             4.6\n",
       "1666      2.336570             6.4\n",
       "649       1.844455             4.5\n",
       "37        2.247237             5.8\n",
       "1286      2.380033             6.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compare['ErrorRate']= df_compare.apply(lambda row: abs(row['valence_pred']-row['valence_target'])/row['valence_target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    595.000000\n",
       "mean       0.527808\n",
       "std        0.103227\n",
       "min        0.016969\n",
       "25%        0.476123\n",
       "50%        0.545702\n",
       "75%        0.598228\n",
       "max        0.729439\n",
       "Name: ErrorRate, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare['ErrorRate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92713670924369751"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfRandom = RandomForestRegressor()\n",
    "clfRandom.fit(X_train, y_train['valence_mean'])\n",
    "y_pred_valence_RandomF = clfRandom.predict(X_test)\n",
    "mean_squared_error(y_test['valence_mean'], y_pred_valence_RandomF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, fileName):\n",
    "    f = open('./'+fileName, 'wb')\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_model(clf_valence, \"valence_model.sav\")\n",
    "save_model(clf_arousal, \"arousal_model.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = [ 0.65519038, -0.07628927, -0.77544214, -0.03422748, -0.76500356,\n",
    "        0.62507754,  0.2090739 , -0.23296932,  0.16704597,  0.30380077,\n",
    "       -0.12093146,  0.84937125,  0.6236305 , -0.73196571,  1.23342518,\n",
    "        0.64840883, -0.29515861,  0.66941854,  0.67054655,  0.07763418,\n",
    "        0.35497932,  0.65683281, -0.80359708, -0.09453569,  0.11972583,\n",
    "        0.34251675,  0.6077862 , -0.7165535 , -0.99956607, -0.43536672,\n",
    "        0.91738949,  0.36843219,  0.42423349]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature2= data.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.74550000e+02,  -2.16060000e+02,   8.83100000e+01,\n",
       "        -8.95000000e+00,   4.18900000e+01,   1.89700000e+01,\n",
       "         7.79000000e+00,  -2.24000000e+00,   5.94000000e+00,\n",
       "         0.00000000e+00,   5.36000000e+00,   2.07000000e+00,\n",
       "         2.31000000e+00,  -6.30000000e+00,   4.57000000e+00,\n",
       "         8.40000000e-01,   4.87000000e+00,  -9.80000000e+00,\n",
       "        -3.50000000e+00,  -7.39000000e+00,   9.04000000e+00,\n",
       "         3.60000000e-01,   1.50000000e-01,   2.50000000e-01,\n",
       "         2.10000000e-01,   4.40000000e-01,   2.10000000e-01,\n",
       "         9.00000000e-02,   1.80000000e-01,   3.10000000e-01,\n",
       "         6.70000000e-01,   4.00000000e-01,   5.30000000e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index           2.0\n",
       "song_id         4.0\n",
       "valence_mean    5.7\n",
       "arousal_mean    5.5\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open('./valence_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.01894236], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create k-fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=7).split(X_train)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paraSearch(model, x_train, y_train, parameters):\n",
    "    gs = GridSearchCV(model, parameters, cv=5, scoring=scorer)\n",
    "    gs.fit(x_train, y_train)\n",
    "    return gs.best_params_, gs.best_score_, gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBRegressor\n",
    "xgb_params = {\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'learning_rate': [0.075, 0.05, 0.03, 0.01],\n",
    "    'max_depth': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'reg_alpha': [0, 0.1, 0.3, 0.5],\n",
    "    'reg_lambda': [0.1, 0.5, 0.7, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 13,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 50,\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0.5,\n",
       "  'subsample': 0.5},\n",
       " 8.4837638608433714,\n",
       " XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "        gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=13,\n",
       "        min_child_weight=1, missing=None, n_estimators=50, nthread=-1,\n",
       "        objective='reg:linear', reg_alpha=0, reg_lambda=0.5,\n",
       "        scale_pos_weight=1, seed=0, silent=True, subsample=0.5))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraSearch(clf, X_train, y_train['valence_mean'], xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_finetune =  XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
    "        gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=7,\n",
    "        min_child_weight=3, missing=None, n_estimators=100, nthread=-1,\n",
    "        objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "        scale_pos_weight=1, seed=0, silent=True, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_finetune.fit(X_train, y_train['valence_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_finetune = clf_finetune.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test['valence_mean'], y_pred_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import any_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiments(\n",
    "        experimental_run,\n",
    "        dataset,\n",
    "        model_class=XGBR,\n",
    "        loss=LOG_LOSS,\n",
    "        test_metric=accuracy_score,\n",
    "        random_state=None,\n",
    "        dataset_name=None):\n",
    "    \"\"\"\n",
    "    Basic experimental framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    experimental_run : list of tuples\n",
    "        These tuples should have exactly three members: the first one\n",
    "        of `grid_search`, `randomized_search`, `hyperopt_search`,\n",
    "        `skopt_gp_minimize`, `skopt_forest_minimize`, or\n",
    "        `skopt_forest_gbrt`, the second an appropriate `param_grid`\n",
    "        dict for that function, and the third a dict specifying\n",
    "        keyword arguments to the search function.\n",
    "    dataset : (np.array, iterable)\n",
    "        A dataset (X, y) where `X` has dimension\n",
    "        `(n_samples, n_features)` and `y` has\n",
    "         dimension `n_samples`.\n",
    "    \n",
    "    model_class : classifier\n",
    "        A classifier model in the mode of `sklearn`, with at least\n",
    "        `fit` and `predict` methods operating on things like\n",
    "        `X` and `y`.\n",
    "    loss : function or string\n",
    "        An appropriate loss function or string recognizable by\n",
    "        `sklearn.cross_validation.cross_val_score`. In `sklearn`, scores\n",
    "        are positive and losses are negative because they maximize,\n",
    "        but here we are minimizing so we always want smaller to mean\n",
    "        better.\n",
    "    test_metric : function\n",
    "        An `sklearn.metrics` function.\n",
    "    random_state : int\n",
    "    dataset_name : str or None\n",
    "        Informal name to give the dataset. Purely for\n",
    "        book-keeping.\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "       Each dict is a results dictionary of the sort returned\n",
    "       by `assess`.\n",
    "    \"\"\"                    \n",
    "    X, y = dataset    \n",
    "    skf = get_cross_validation_indices(\n",
    "        X, y, random_state=random_state)        \n",
    "    all_results = []\n",
    "    # This loop can easily be parallelized, but doing so can\n",
    "    # be tricky on some systems, since `cross_val_score`\n",
    "    # calls `joblib` even if `n_jobs=1`, resulting in\n",
    "    # nested parallel jobs even if there is no actual\n",
    "    # parallelization elsewhere in the experimental run.\n",
    "    for search_func, param_grid, kwargs in experimental_run:\n",
    "        print(search_func.__name__)\n",
    "        all_results.append(\n",
    "            assess(\n",
    "                X, y,                \n",
    "                search_func=search_func, \n",
    "                model_class=XGBClassifier, \n",
    "                param_grid=param_grid,\n",
    "                xval_indices=skf,\n",
    "                loss=loss,\n",
    "                test_metric=test_metric,                \n",
    "                dataset_name=dataset_name,\n",
    "                search_func_args=kwargs))\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.var>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "itemset must have at least one argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c8d4fa9dcee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: itemset must have at least one argument"
     ]
    }
   ],
   "source": [
    "a.itemset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
