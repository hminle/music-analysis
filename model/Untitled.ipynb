{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/dfLongterm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea1</th>\n",
       "      <th>fea2</th>\n",
       "      <th>fea3</th>\n",
       "      <th>fea4</th>\n",
       "      <th>fea5</th>\n",
       "      <th>fea6</th>\n",
       "      <th>fea7</th>\n",
       "      <th>fea8</th>\n",
       "      <th>fea9</th>\n",
       "      <th>fea10</th>\n",
       "      <th>...</th>\n",
       "      <th>fea24</th>\n",
       "      <th>fea25</th>\n",
       "      <th>fea26</th>\n",
       "      <th>fea27</th>\n",
       "      <th>fea28</th>\n",
       "      <th>fea29</th>\n",
       "      <th>fea30</th>\n",
       "      <th>fea31</th>\n",
       "      <th>fea32</th>\n",
       "      <th>fea33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.14</td>\n",
       "      <td>-210.30</td>\n",
       "      <td>70.38</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>13.52</td>\n",
       "      <td>7.67</td>\n",
       "      <td>9.21</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.00</td>\n",
       "      <td>-321.79</td>\n",
       "      <td>105.26</td>\n",
       "      <td>16.30</td>\n",
       "      <td>33.23</td>\n",
       "      <td>11.20</td>\n",
       "      <td>28.95</td>\n",
       "      <td>12.95</td>\n",
       "      <td>16.30</td>\n",
       "      <td>2.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174.55</td>\n",
       "      <td>-216.06</td>\n",
       "      <td>88.31</td>\n",
       "      <td>-8.95</td>\n",
       "      <td>41.89</td>\n",
       "      <td>18.97</td>\n",
       "      <td>7.79</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.23</td>\n",
       "      <td>-185.45</td>\n",
       "      <td>85.01</td>\n",
       "      <td>-8.47</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-17.62</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-14.41</td>\n",
       "      <td>-8.74</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.00</td>\n",
       "      <td>-209.14</td>\n",
       "      <td>69.00</td>\n",
       "      <td>30.20</td>\n",
       "      <td>31.84</td>\n",
       "      <td>14.17</td>\n",
       "      <td>22.39</td>\n",
       "      <td>5.16</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fea1    fea2    fea3   fea4   fea5   fea6   fea7   fea8   fea9  fea10  \\\n",
       "0  137.14 -210.30   70.38  -1.80  13.52   7.67   9.21  -4.23   3.85  -2.07   \n",
       "1   96.00 -321.79  105.26  16.30  33.23  11.20  28.95  12.95  16.30   2.92   \n",
       "2  174.55 -216.06   88.31  -8.95  41.89  18.97   7.79  -2.24   5.94   0.00   \n",
       "3   49.23 -185.45   85.01  -8.47   3.75 -17.62   6.10 -14.41  -8.74  -7.15   \n",
       "4  120.00 -209.14   69.00  30.20  31.84  14.17  22.39   5.16  12.23   0.63   \n",
       "\n",
       "   ...    fea24  fea25  fea26  fea27  fea28  fea29  fea30  fea31  fea32  fea33  \n",
       "0  ...     0.33   0.34   0.41   0.43   0.20   0.17   0.26   0.54   0.42   0.45  \n",
       "1  ...     0.55   0.59   0.41   0.38   0.27   0.22   0.09   0.05   0.12   0.25  \n",
       "2  ...     0.25   0.21   0.44   0.21   0.09   0.18   0.31   0.67   0.40   0.53  \n",
       "3  ...     0.24   0.50   0.53   0.20   0.26   0.09   0.14   0.17   0.31   0.33  \n",
       "4  ...     0.03   0.06   0.12   0.22   0.23   0.18   0.17   0.17   0.43   0.82  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('../data/dfY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>arousal_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  song_id  valence_mean  arousal_mean\n",
       "0      0        2           3.1           3.0\n",
       "1      1        3           3.5           3.3\n",
       "2      2        4           5.7           5.5\n",
       "3      3        5           4.4           5.3\n",
       "4      4        7           5.8           6.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y['valence_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y['arousal_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([data,y['valence_mean'], y['arousal_mean']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15 #number of variables for heatmap\n",
    "corrmat = df.corr()\n",
    "cols = corrmat.nlargest(k, 'valence_mean')['valence_mean'].index\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scaled = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea1</th>\n",
       "      <th>fea2</th>\n",
       "      <th>fea3</th>\n",
       "      <th>fea4</th>\n",
       "      <th>fea5</th>\n",
       "      <th>fea6</th>\n",
       "      <th>fea7</th>\n",
       "      <th>fea8</th>\n",
       "      <th>fea9</th>\n",
       "      <th>fea10</th>\n",
       "      <th>...</th>\n",
       "      <th>fea24</th>\n",
       "      <th>fea25</th>\n",
       "      <th>fea26</th>\n",
       "      <th>fea27</th>\n",
       "      <th>fea28</th>\n",
       "      <th>fea29</th>\n",
       "      <th>fea30</th>\n",
       "      <th>fea31</th>\n",
       "      <th>fea32</th>\n",
       "      <th>fea33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655190</td>\n",
       "      <td>-0.076289</td>\n",
       "      <td>-0.775442</td>\n",
       "      <td>-0.034227</td>\n",
       "      <td>-0.765004</td>\n",
       "      <td>0.625078</td>\n",
       "      <td>0.209074</td>\n",
       "      <td>-0.232969</td>\n",
       "      <td>0.167046</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>0.119726</td>\n",
       "      <td>0.342517</td>\n",
       "      <td>0.607786</td>\n",
       "      <td>-0.716554</td>\n",
       "      <td>-0.999566</td>\n",
       "      <td>-0.435367</td>\n",
       "      <td>0.917389</td>\n",
       "      <td>0.368432</td>\n",
       "      <td>0.424233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.697601</td>\n",
       "      <td>-1.237927</td>\n",
       "      <td>0.141235</td>\n",
       "      <td>0.678357</td>\n",
       "      <td>0.547352</td>\n",
       "      <td>0.926323</td>\n",
       "      <td>1.939007</td>\n",
       "      <td>1.843453</td>\n",
       "      <td>1.536770</td>\n",
       "      <td>0.989698</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096746</td>\n",
       "      <td>1.603536</td>\n",
       "      <td>0.342517</td>\n",
       "      <td>0.318272</td>\n",
       "      <td>-0.294819</td>\n",
       "      <td>-0.719813</td>\n",
       "      <td>-1.472541</td>\n",
       "      <td>-1.818019</td>\n",
       "      <td>-1.379786</td>\n",
       "      <td>-0.709320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.885329</td>\n",
       "      <td>-0.136304</td>\n",
       "      <td>-0.304226</td>\n",
       "      <td>-0.315718</td>\n",
       "      <td>1.123963</td>\n",
       "      <td>1.589404</td>\n",
       "      <td>0.084631</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.396984</td>\n",
       "      <td>0.588331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527729</td>\n",
       "      <td>-0.651855</td>\n",
       "      <td>0.509935</td>\n",
       "      <td>-0.666075</td>\n",
       "      <td>-1.379279</td>\n",
       "      <td>-0.943615</td>\n",
       "      <td>-0.130315</td>\n",
       "      <td>1.643110</td>\n",
       "      <td>0.251884</td>\n",
       "      <td>0.877655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.235521</td>\n",
       "      <td>0.182628</td>\n",
       "      <td>-0.390953</td>\n",
       "      <td>-0.296821</td>\n",
       "      <td>-1.415522</td>\n",
       "      <td>-1.533136</td>\n",
       "      <td>-0.063474</td>\n",
       "      <td>-1.463352</td>\n",
       "      <td>-1.218080</td>\n",
       "      <td>-0.394467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581878</td>\n",
       "      <td>1.069364</td>\n",
       "      <td>1.012190</td>\n",
       "      <td>-0.723977</td>\n",
       "      <td>-0.355067</td>\n",
       "      <td>-1.447171</td>\n",
       "      <td>-1.167490</td>\n",
       "      <td>-1.148123</td>\n",
       "      <td>-0.272581</td>\n",
       "      <td>-0.255899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091582</td>\n",
       "      <td>-0.064203</td>\n",
       "      <td>-0.811710</td>\n",
       "      <td>1.225590</td>\n",
       "      <td>0.454802</td>\n",
       "      <td>1.179779</td>\n",
       "      <td>1.364115</td>\n",
       "      <td>0.901932</td>\n",
       "      <td>1.088996</td>\n",
       "      <td>0.674927</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.719011</td>\n",
       "      <td>-1.542141</td>\n",
       "      <td>-1.275859</td>\n",
       "      <td>-0.608172</td>\n",
       "      <td>-0.535810</td>\n",
       "      <td>-0.943615</td>\n",
       "      <td>-0.984459</td>\n",
       "      <td>-1.148123</td>\n",
       "      <td>0.426706</td>\n",
       "      <td>2.521308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fea1      fea2      fea3      fea4      fea5      fea6      fea7  \\\n",
       "0  0.655190 -0.076289 -0.775442 -0.034227 -0.765004  0.625078  0.209074   \n",
       "1 -0.697601 -1.237927  0.141235  0.678357  0.547352  0.926323  1.939007   \n",
       "2  1.885329 -0.136304 -0.304226 -0.315718  1.123963  1.589404  0.084631   \n",
       "3 -2.235521  0.182628 -0.390953 -0.296821 -1.415522 -1.533136 -0.063474   \n",
       "4  0.091582 -0.064203 -0.811710  1.225590  0.454802  1.179779  1.364115   \n",
       "\n",
       "       fea8      fea9     fea10    ...        fea24     fea25     fea26  \\\n",
       "0 -0.232969  0.167046  0.303801    ...    -0.094536  0.119726  0.342517   \n",
       "1  1.843453  1.536770  0.989698    ...     1.096746  1.603536  0.342517   \n",
       "2  0.007548  0.396984  0.588331    ...    -0.527729 -0.651855  0.509935   \n",
       "3 -1.463352 -1.218080 -0.394467    ...    -0.581878  1.069364  1.012190   \n",
       "4  0.901932  1.088996  0.674927    ...    -1.719011 -1.542141 -1.275859   \n",
       "\n",
       "      fea27     fea28     fea29     fea30     fea31     fea32     fea33  \n",
       "0  0.607786 -0.716554 -0.999566 -0.435367  0.917389  0.368432  0.424233  \n",
       "1  0.318272 -0.294819 -0.719813 -1.472541 -1.818019 -1.379786 -0.709320  \n",
       "2 -0.666075 -1.379279 -0.943615 -0.130315  1.643110  0.251884  0.877655  \n",
       "3 -0.723977 -0.355067 -1.447171 -1.167490 -1.148123 -0.272581 -0.255899  \n",
       "4 -0.608172 -0.535810 -0.943615 -0.984459 -1.148123  0.426706  2.521308  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelTest(clf, train, labels):\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=45).split(train)\n",
    "    mse = make_scorer(mean_squared_error)\n",
    "    mse_val_score = cross_val_score(clf, train, labels, cv=cv, scoring=mse)\n",
    "    scores=[mse_val_score.mean()]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelPlot(result_dict):\n",
    "    result = pd.DataFrame.from_dict(result_dict, orient='index')\n",
    "    result.columns = [\"Mean Squared Error\"] \n",
    "    result = result.sort(columns=[\"Mean Squared Error\"],ascending=False)\n",
    "    #print(result)\n",
    "    result.plot(kind=\"bar\",title=\"Model Scores\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.5,1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelFit(train, labels):\n",
    "    result_dict = {}\n",
    "    \n",
    "    clf = linear_model.LinearRegression()\n",
    "    result_dict[\"Linear\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=1e-4)\n",
    "    result_dict[\"Lasso\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.Ridge()\n",
    "    result_dict[\"Ridge\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.BayesianRidge()\n",
    "    result_dict[\"Bayesian Ridge\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.HuberRegressor()\n",
    "    result_dict[\"Huber\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    result_dict[\"SVM RBF\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = svm.SVR(kernel=\"linear\")\n",
    "    result_dict[\"SVM Linear\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = BaggingRegressor()\n",
    "    result_dict[\"Bagging\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    result_dict[\"RandomForest\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = AdaBoostRegressor()\n",
    "    result_dict[\"AdaBoost\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    result_dict[\"XGBoost\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    model_summary = modelPlot(result_dict)\n",
    "    return model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFit(data_scaled, y['valence_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train['valence_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test['valence_mean'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame({\"valence_target\": y_test['valence_mean'], \"valence_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compare['ErrorRate']= df_compare.apply(lambda row: abs(row['valence_pred']-row['valence_target'])/row['valence_target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare['ErrorRate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create k-fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=7).split(X_train)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paraSearch(model, x_train, y_train, parameters):\n",
    "    gs = GridSearchCV(model, parameters, cv=5, scoring=scorer)\n",
    "    gs.fit(x_train, y_train)\n",
    "    return gs.best_params_, gs.best_score_, gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBRegressor\n",
    "xgb_params = {\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'learning_rate': [0.075, 0.05, 0.03, 0.01],\n",
    "    'max_depth': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'reg_alpha': [0, 0.1, 0.3, 0.5],\n",
    "    'reg_lambda': [0.1, 0.5, 0.7, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 13,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 50,\n",
       "  'reg_alpha': 0,\n",
       "  'reg_lambda': 0.5,\n",
       "  'subsample': 0.5},\n",
       " 8.4837638608433714,\n",
       " XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "        gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=13,\n",
       "        min_child_weight=1, missing=None, n_estimators=50, nthread=-1,\n",
       "        objective='reg:linear', reg_alpha=0, reg_lambda=0.5,\n",
       "        scale_pos_weight=1, seed=0, silent=True, subsample=0.5))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraSearch(clf, X_train, y_train['valence_mean'], xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_finetune =  XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
    "        gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=7,\n",
    "        min_child_weight=3, missing=None, n_estimators=100, nthread=-1,\n",
    "        objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "        scale_pos_weight=1, seed=0, silent=True, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_finetune.fit(X_train, y_train['valence_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_finetune = clf_finetune.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test['valence_mean'], y_pred_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import any_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(\n",
    "        experimental_run,\n",
    "        dataset,\n",
    "        model_class=XGBR,\n",
    "        loss=LOG_LOSS,\n",
    "        test_metric=accuracy_score,\n",
    "        random_state=None,\n",
    "        dataset_name=None):\n",
    "    \"\"\"\n",
    "    Basic experimental framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    experimental_run : list of tuples\n",
    "        These tuples should have exactly three members: the first one\n",
    "        of `grid_search`, `randomized_search`, `hyperopt_search`,\n",
    "        `skopt_gp_minimize`, `skopt_forest_minimize`, or\n",
    "        `skopt_forest_gbrt`, the second an appropriate `param_grid`\n",
    "        dict for that function, and the third a dict specifying\n",
    "        keyword arguments to the search function.\n",
    "    dataset : (np.array, iterable)\n",
    "        A dataset (X, y) where `X` has dimension\n",
    "        `(n_samples, n_features)` and `y` has\n",
    "         dimension `n_samples`.\n",
    "    \n",
    "    model_class : classifier\n",
    "        A classifier model in the mode of `sklearn`, with at least\n",
    "        `fit` and `predict` methods operating on things like\n",
    "        `X` and `y`.\n",
    "    loss : function or string\n",
    "        An appropriate loss function or string recognizable by\n",
    "        `sklearn.cross_validation.cross_val_score`. In `sklearn`, scores\n",
    "        are positive and losses are negative because they maximize,\n",
    "        but here we are minimizing so we always want smaller to mean\n",
    "        better.\n",
    "    test_metric : function\n",
    "        An `sklearn.metrics` function.\n",
    "    random_state : int\n",
    "    dataset_name : str or None\n",
    "        Informal name to give the dataset. Purely for\n",
    "        book-keeping.\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "       Each dict is a results dictionary of the sort returned\n",
    "       by `assess`.\n",
    "    \"\"\"                    \n",
    "    X, y = dataset    \n",
    "    skf = get_cross_validation_indices(\n",
    "        X, y, random_state=random_state)        \n",
    "    all_results = []\n",
    "    # This loop can easily be parallelized, but doing so can\n",
    "    # be tricky on some systems, since `cross_val_score`\n",
    "    # calls `joblib` even if `n_jobs=1`, resulting in\n",
    "    # nested parallel jobs even if there is no actual\n",
    "    # parallelization elsewhere in the experimental run.\n",
    "    for search_func, param_grid, kwargs in experimental_run:\n",
    "        print(search_func.__name__)\n",
    "        all_results.append(\n",
    "            assess(\n",
    "                X, y,                \n",
    "                search_func=search_func, \n",
    "                model_class=XGBClassifier, \n",
    "                param_grid=param_grid,\n",
    "                xval_indices=skf,\n",
    "                loss=loss,\n",
    "                test_metric=test_metric,                \n",
    "                dataset_name=dataset_name,\n",
    "                search_func_args=kwargs))\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
