{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from outlier_cleaner import outlierCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/dfLongterm.csv')\n",
    "y = pd.read_csv('../data/dfY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([data,y['valence_mean'], y['arousal_mean']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "k = 15 #number of variables for heatmap\n",
    "corrmat = df.corr()\n",
    "cols = corrmat.nlargest(k, 'valence_mean')['valence_mean'].index\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()\n",
    "#plt.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cleaner(df, x, y):\n",
    "    \"\"\"\n",
    "    x, y: dataframe\n",
    "    \"\"\"\n",
    "    #convert to numpy array\n",
    "    x = np.reshape(np.array(df[x]), (len(df), 1))\n",
    "    y = np.reshape(np.array(df[y]), (len(df), 1))\n",
    "    \n",
    "    #fit\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(x, y)\n",
    "    predictions = reg.predict(x)\n",
    "    cleaned_list = outlierCleaner(predictions, x, y)[1] #return a list of outlier values\n",
    "    cleaned_list =  np.reshape(np.array(cleaned_list), (len(cleaned_list), 1))\n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valence_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "x = 'MFCC1'\n",
    "y = 'valence_mean'\n",
    "temp = pd.concat([df[y], df[x]], axis=1)\n",
    "temp.plot.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MFCC1\n",
    "cleaned_list = Cleaner(df, x, y)\n",
    "for i in cleaned_list:\n",
    "    df = df[df.fea2 != i[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arousal_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "x = 'MFCC1'\n",
    "y = 'arousal_mean'\n",
    "temp = pd.concat([df[y], df[x]], axis=1)\n",
    "temp.plot.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fea2\n",
    "cleaned_list = Cleaner(df, 'MFCC1', 'arousal_mean')\n",
    "for i in cleaned_list:\n",
    "    df = df[df.fea2 != i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_list.shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df.drop(['valence_mean', 'arousal_mean'], 1)\n",
    "y = pd.concat([df['valence_mean'], df['arousal_mean']],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaler.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelTest(clf, train, labels):\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=45).split(train)\n",
    "    mse = make_scorer(mean_squared_error)\n",
    "    mse_val_score = cross_val_score(clf, train, labels, cv=cv, scoring=mse)\n",
    "    scores=[mse_val_score.mean()]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelPlot(result_dict):\n",
    "    result = pd.DataFrame.from_dict(result_dict, orient='index')\n",
    "    result.columns = [\"Mean Squared Error\"] \n",
    "    result = result.sort(columns=[\"Mean Squared Error\"],ascending=False)\n",
    "    #print(result)\n",
    "    result.plot(kind=\"bar\",title=\"Model Scores\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.5,1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelFit(train, labels):\n",
    "    result_dict = {}\n",
    "    '''\n",
    "    clf = linear_model.LinearRegression()\n",
    "    result_dict[\"Linear\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=1e-4)\n",
    "    result_dict[\"Lasso\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.Ridge()\n",
    "    result_dict[\"Ridge\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.BayesianRidge()\n",
    "    result_dict[\"Bayesian Ridge\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = linear_model.HuberRegressor()\n",
    "    result_dict[\"Huber\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    result_dict[\"SVM RBF\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = svm.SVR(kernel=\"linear\")\n",
    "    result_dict[\"SVM Linear\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = BaggingRegressor()\n",
    "    result_dict[\"Bagging\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    result_dict[\"RandomForest\"] = modelTest(clf, train, labels)\n",
    "    '''\n",
    "    clf = AdaBoostRegressor()\n",
    "    result_dict[\"AdaBoost\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    clf = XGBRegressor()\n",
    "    result_dict[\"XGBoost\"] = modelTest(clf, train, labels)\n",
    "    \n",
    "    model_summary = modelPlot(result_dict)\n",
    "    return model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "modelFit(data_scaled, y['valence_mean'])\n",
    "#modelFit(data, y['valence_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_model(model, data, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    sns.regplot(x=y_pred, y=y_test)\n",
    "    print(np.corrcoef(y_pred, y_test))\n",
    "    print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_valence = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_model(clf_valence, data_scaled.as_matrix(), np.array(y['valence_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_arousal = XGBRegressor()\n",
    "create_model(clf_arousal, data_scaled.as_matrix(), np.array(y['arousal_mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reference about correlation metric to evaluate model\n",
    "http://imgur.com/a/gX89A\n",
    "\n",
    "https://classroom.udacity.com/courses/ud501/lessons/4802891095/concepts/49196894850923"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 30, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_importance(clf_valence, height=0.5)\n",
    "plt.savefig('feas_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_valence.booster().get_fscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Remove feature and re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_removed = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del data_removed['fea13']\n",
    "del data_removed['fea22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_valence_removed = XGBRegressor()\n",
    "create_model(clf_valence_removed, data_removed.as_matrix(), np.array(y['valence_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_valence_removed.booster().get_fscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "# Experiment with different model and show error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_arousal_ridge = linear_model.Ridge()\n",
    "create_model(clf_arousal_ridge, data_scaled, np.array(y['arousal_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_compare_arousal = pd.DataFrame({\"arousal_target\": y_test['arousal_mean'], \"arousal_pred\": y_pred_arousal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_compare_arousal['ErrorRate']= df_compare_arousal.apply(lambda row: abs(row['arousal_pred']-row['arousal_target'])/row['arousal_target'], axis=1)\n",
    "df_compare_arousal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame({\"valence_target\": y_test['valence_mean'], \"valence_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_compare['ErrorRate']= df_compare.apply(lambda row: abs(row['valence_pred']-row['valence_target'])/row['valence_target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_compare['ErrorRate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clfRandom = RandomForestRegressor()\n",
    "clfRandom.fit(X_train, y_train['valence_mean'])\n",
    "y_pred_valence_RandomF = clfRandom.predict(X_test)\n",
    "mean_squared_error(y_test['valence_mean'], y_pred_valence_RandomF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, fileName):\n",
    "    f = open('./'+fileName, 'wb')\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_model(clf_valence, \"valence_model.sav\")\n",
    "save_model(clf_arousal, \"arousal_model.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature = [ 0.65519038, -0.07628927, -0.77544214, -0.03422748, -0.76500356,\n",
    "        0.62507754,  0.2090739 , -0.23296932,  0.16704597,  0.30380077,\n",
    "       -0.12093146,  0.84937125,  0.6236305 , -0.73196571,  1.23342518,\n",
    "        0.64840883, -0.29515861,  0.66941854,  0.67054655,  0.07763418,\n",
    "        0.35497932,  0.65683281, -0.80359708, -0.09453569,  0.11972583,\n",
    "        0.34251675,  0.6077862 , -0.7165535 , -0.99956607, -0.43536672,\n",
    "        0.91738949,  0.36843219,  0.42423349]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature2= data.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.array(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open('./valence_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create k-fold\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=7).split(X_train)\n",
    "#scorer = make_scorer(mean_squared_error, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def paraSearch(model, data, y, parameters):\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=7)\n",
    "    gs = GridSearchCV(model, parameters, cv=5, scoring=scorer)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_params_, gs.best_score_, gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#XGBRegressor\n",
    "xgb_params = {\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'learning_rate': [0.075, 0.05, 0.03, 0.01, 0.1, 0.5],\n",
    "    'max_depth': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'reg_alpha': [0, 0.1, 0.3, 0.5, 0.7, 1],\n",
    "    'reg_lambda': [0.1, 0.5, 0.7, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "paraSearch(clf_valence, data, y['valence_mean'], xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_finetune =  XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "        gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=13,\n",
    "        min_child_weight=1, missing=None, n_estimators=50, nthread=-1,\n",
    "        objective='reg:linear', reg_alpha=0, reg_lambda=0.5,\n",
    "        scale_pos_weight=1, seed=0, silent=True, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_model(clf_finetune, data.as_matrix(), y['arousal_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred_finetune = clf_finetune.predict(data.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfPredValenceFinetune=pd.DataFrame(y_pred_finetune, columns=['valence_mean_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dfPredValenceFinetune, open('./dfPredValenceFinetune', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfPredValenceFinetune.to_csv('./y_pred_arousal_finetune.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y['valence_mean'], y_pred_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test['valence_mean'], y_pred_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import any_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_experiments(\n",
    "        experimental_run,\n",
    "        dataset,\n",
    "        model_class=XGBR,\n",
    "        loss=LOG_LOSS,\n",
    "        test_metric=accuracy_score,\n",
    "        random_state=None,\n",
    "        dataset_name=None):\n",
    "    \"\"\"\n",
    "    Basic experimental framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    experimental_run : list of tuples\n",
    "        These tuples should have exactly three members: the first one\n",
    "        of `grid_search`, `randomized_search`, `hyperopt_search`,\n",
    "        `skopt_gp_minimize`, `skopt_forest_minimize`, or\n",
    "        `skopt_forest_gbrt`, the second an appropriate `param_grid`\n",
    "        dict for that function, and the third a dict specifying\n",
    "        keyword arguments to the search function.\n",
    "    dataset : (np.array, iterable)\n",
    "        A dataset (X, y) where `X` has dimension\n",
    "        `(n_samples, n_features)` and `y` has\n",
    "         dimension `n_samples`.\n",
    "    \n",
    "    model_class : classifier\n",
    "        A classifier model in the mode of `sklearn`, with at least\n",
    "        `fit` and `predict` methods operating on things like\n",
    "        `X` and `y`.\n",
    "    loss : function or string\n",
    "        An appropriate loss function or string recognizable by\n",
    "        `sklearn.cross_validation.cross_val_score`. In `sklearn`, scores\n",
    "        are positive and losses are negative because they maximize,\n",
    "        but here we are minimizing so we always want smaller to mean\n",
    "        better.\n",
    "    test_metric : function\n",
    "        An `sklearn.metrics` function.\n",
    "    random_state : int\n",
    "    dataset_name : str or None\n",
    "        Informal name to give the dataset. Purely for\n",
    "        book-keeping.\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "       Each dict is a results dictionary of the sort returned\n",
    "       by `assess`.\n",
    "    \"\"\"                    \n",
    "    X, y = dataset    \n",
    "    skf = get_cross_validation_indices(\n",
    "        X, y, random_state=random_state)        \n",
    "    all_results = []\n",
    "    # This loop can easily be parallelized, but doing so can\n",
    "    # be tricky on some systems, since `cross_val_score`\n",
    "    # calls `joblib` even if `n_jobs=1`, resulting in\n",
    "    # nested parallel jobs even if there is no actual\n",
    "    # parallelization elsewhere in the experimental run.\n",
    "    for search_func, param_grid, kwargs in experimental_run:\n",
    "        print(search_func.__name__)\n",
    "        all_results.append(\n",
    "            assess(\n",
    "                X, y,                \n",
    "                search_func=search_func, \n",
    "                model_class=XGBClassifier, \n",
    "                param_grid=param_grid,\n",
    "                xval_indices=skf,\n",
    "                loss=loss,\n",
    "                test_metric=test_metric,                \n",
    "                dataset_name=dataset_name,\n",
    "                search_func_args=kwargs))\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a.itemset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pydata35]",
   "language": "python",
   "name": "conda-env-pydata35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
